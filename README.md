# Deepfake Image Classification - CNN & MLP Models

This repository contains two machine learning models developed for the [**Deepfake Classification - UniBuc Competition**](https://www.kaggle.com/competitions/deepfake-classification-unibuc/overview) hosted on Kaggle.

The challenge focused on detecting **AI-generated (deepfake) faces**, requiring participants to train classifiers that distinguish between authentic and synthetically generated images.  

This is a **multi-class classification** task, where each image must be classified into one of **five classes** (0 to 4).

## ğŸ—‚ï¸ Dataset Overview

- **Training set:** 12,500 images  
- **Validation set:** 1,250 images  
- **Test set:** 6,500 images  

### ğŸ“„ Metadata files:
- `train.csv` â€“ image filenames + labels
- `validation.csv` â€“ validation filenames + labels
- `test.csv` â€“ test image filenames (no labels)
- `sample_submission.csv` â€“ submission format reference

All images are provided in **.png format** and are paired with metadata files in **CSV format** (`image_id,label`).

## ğŸ“ Project Structure
- `model_andra_cnn_final.py` â€“ Deep Convolutional Neural Network for image classification
- `model_andra_mlp.py` â€“ Multilayer Perceptron trained on flattened image data
- `Andruta_AndraMihaela_232_doc.pdf` â€“ ğŸ“„ Full documentation with technical explanation and experiments

## Model Architectures
### ğŸ§  Convolutional Neural Network (CNN) Architecture

The CNN model is designed to extract spatial features from RGB images and classify them into one of 5 deepfake classes.

It consists of 4 convolutional blocks, each followed by Batch Normalization, ReLU activation, and MaxPooling. Dropout regularization is applied before and after the first fully connected layer to reduce overfitting.

### ğŸ”§ Architecture Overview:

- **Input:** RGB image (3 channels)
- **Conv Block 1:**  
  - `Conv2D(3 â†’ 16)` â†’ `BatchNorm2D(16)` â†’ `ReLU` â†’ `MaxPool(2x2)`
- **Conv Block 2:**  
  - `Conv2D(16 â†’ 32)` â†’ `BatchNorm2D(32)` â†’ `ReLU` â†’ `MaxPool(2x2)`
- **Conv Block 3:**  
  - `Conv2D(32 â†’ 64)` â†’ `BatchNorm2D(64)` â†’ `ReLU` â†’ `MaxPool(2x2)`
- **Conv Block 4:**  
  - `Conv2D(64 â†’ 128)` â†’ `BatchNorm2D(128)` â†’ `ReLU` â†’ `MaxPool(2x2)`
- **Flatten:**  
  - Output of size `128 x 8 x 8` flattened to `8192` features
- **Fully Connected Layer 1:**  
  - `Linear(8192 â†’ 256)` â†’ `ReLU` â†’ `Dropout(0.3)`
- **Fully Connected Layer 2 (Output):**  
  - `Linear(256 â†’ 5)` (for 5-class classification)

### ğŸ§ª Regularization:
- **Batch Normalization:** After every convolution for stable training
- **Dropout:** 30% dropout rate to reduce overfitting in FC layers

### ğŸ—‚ï¸ Output:
- Final layer outputs 5 logits corresponding to the deepfake class predictions.

---

### ğŸ§  Multilayer Perceptron (MLP) Architecture

This MLP model acts as a baseline for deepfake image classification by learning directly from flattened pixel data.  

The model gradually reduces dimensionality across 3 hidden layers and uses LeakyReLU activations to mitigate the "dying ReLU" problem. Dropout is applied to reduce overfitting during training.

### ğŸ”§ Architecture Overview:

- **Input:** RGB image (3 channels, 128x128 pixels)  
  â†’ Flattened to a `49,152-dimensional vector` (3 Ã— 128 Ã— 128)

- **Hidden Layer 1:**  
  - `Linear(49,152 â†’ 1024)`  
  - `LeakyReLU(Î±=0.01)`

- **Hidden Layer 2:**  
  - `Linear(1024 â†’ 512)`  
  - `LeakyReLU(Î±=0.01)`

- **Hidden Layer 3:**  
  - `Linear(512 â†’ 256)`  
  - `LeakyReLU(Î±=0.01)`

- **Dropout:**  
  - `Dropout(p=0.3)` before final layer (used only during training)

- **Output Layer:**  
  - `Linear(256 â†’ 5)` â†’ outputs raw logits for 5-class prediction

### ğŸ§ª Activation & Regularization:

- **LeakyReLU:** Used throughout to preserve gradient flow and avoid dead neurons  
- **Dropout:** 30% of neurons are randomly deactivated during training to reduce overfitting

### ğŸ—‚ï¸ Output:

The final layer outputs a vector of 5 logits corresponding to the probability distribution over the deepfake image classes (0â€“4).

## ğŸ§ª Training & Evaluation
Both models â€” CNN and MLP â€” were trained using CrossEntropyLoss.
Evaluation was done on the validation set, using the following metrics:
- âœ… Accuracy
- ğŸ“‰ Loss over epochs
- ğŸ“ˆ Accuracy over epochs
- ğŸ“Š Confusion Matrix

## âš™ï¸ How to Run
Prepare your local folders and files:

```bash
/train          # training images
/validation     # validation images
/test           # test images


train.csv
validation.csv
test.csv
sample_submission.csv
```

## Train & Evaluate the Models
Run either of the scripts below:

```bash
model_andra_cnn_final.py     # trains & evaluates CNN model
model_andra_mlp.py     # trains & evaluates MLP model
```
### Outputs
- ğŸ“‰ Confusion matrix
- ğŸ“„ Final submission file


## ğŸ“„ Full Documentation
See [**Andruta_AndraMihaela_232_doc.pdf**](https://github.com/andra2602/Deepfake-Classification/blob/main/Andruta_AndraMihaela_232_doc.pdf) for a complete technical breakdown:
- Dataset exploration
- Model architecture choices
- Hyperparameter tuning
- Performance analysis

## ğŸ“Œ Technologies
- Python 3.11
- PyTorch
- torchvision
- pandas, scikit-learn
- matplotlib


